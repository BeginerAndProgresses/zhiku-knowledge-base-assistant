import streamlit as st
import os
from tools.ingestion import ingest_docs, delete_by_source_file
from tools.query_db import query_vector_db, load_vector_db
import tempfile

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå¸ƒå±€
st.set_page_config(page_title="ä¸ªäººçŸ¥è¯†åº“ç®¡ç†åŠ©æ‰‹", layout="wide")
st.title("ğŸ“š ä¸ªäººçŸ¥è¯†åº“ç®¡ç†åŠ©æ‰‹")
st.markdown("---")

# ä¾§è¾¹æ  - æ–‡ä»¶ä¸Šä¼ å’Œç®¡ç†
with st.sidebar:
    st.header("ğŸ“ æ–‡æ¡£ç®¡ç†")
    
    # æ–‡ä»¶ä¸Šä¼ å™¨ - æ·»åŠ ä¸­æ–‡æç¤º
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ æ–‡æ¡£", 
        type=["pdf", "txt", "docx", "md"],
        help="æ”¯æŒçš„æ ¼å¼: PDF, TXT, DOCX, MD",
        accept_multiple_files=False  # åªæ¥å—å•ä¸ªæ–‡ä»¶
    )
    
    # é›†åˆåç§°è¾“å…¥
    collection_name = st.text_input("é›†åˆåç§°", value="knowledge_base", help="ç”¨äºåŒºåˆ†ä¸åŒçš„çŸ¥è¯†åº“é›†åˆ")
    
    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    if uploaded_file is not None:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp_file:
            tmp_file.write(uploaded_file.read())
            temp_path = tmp_file.name
        
        # å¤„ç†æ–‡æ¡£å¹¶æ·»åŠ åˆ°çŸ¥è¯†åº“
        if st.button("ğŸ“¤ æ·»åŠ åˆ°çŸ¥è¯†åº“", use_container_width=True):
            try:
                with st.spinner(f"æ­£åœ¨å¤„ç†æ–‡æ¡£ {uploaded_file.name}..."):
                    vectorstore = ingest_docs(temp_path, collection_name)
                st.success(f"âœ… æ–‡æ¡£ {uploaded_file.name} å·²æˆåŠŸæ·»åŠ åˆ°çŸ¥è¯†åº“!")
                
                # æ˜¾ç¤ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
                st.info(f"æ–‡æ¡£å·²æ·»åŠ åˆ°é›†åˆ '{collection_name}'")
            except Exception as e:
                st.error(f"âŒ å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.unlink(temp_path)
    
    st.markdown("---")
    
    # æ–‡æ¡£åˆ é™¤åŠŸèƒ½
    st.header("ğŸ—‘ï¸ åˆ é™¤æ–‡æ¡£")
    
    # è·å–å½“å‰æ•°æ®åº“ä¸­çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆæ¨¡æ‹Ÿï¼‰
    if st.button("ğŸ”„ åˆ·æ–°æ–‡æ¡£åˆ—è¡¨", use_container_width=True):
        # è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿä»æ•°æ®åº“è·å–æ–‡ä»¶åˆ—è¡¨
        st.session_state.refresh = True
    
    # æ¨¡æ‹Ÿçš„æ–‡ä»¶åˆ—è¡¨ - åœ¨å®é™…åº”ç”¨ä¸­ï¼Œä½ éœ€è¦ä»å‘é‡æ•°æ®åº“ä¸­è·å–
    # è¿™é‡Œæš‚æ—¶ä½¿ç”¨æ–‡æœ¬è¾“å…¥æ¡†è®©ç”¨æˆ·è¾“å…¥è¦åˆ é™¤çš„æ–‡ä»¶å
    file_to_delete = st.text_input("è¾“å…¥è¦åˆ é™¤çš„æ–‡ä»¶å", placeholder="ä¾‹å¦‚: example.pdf")
    
    if st.button("ğŸ—‘ï¸ åˆ é™¤æ–‡æ¡£", use_container_width=True) and file_to_delete:
        try:
            with st.spinner(f"æ­£åœ¨åˆ é™¤æ–‡æ¡£ {file_to_delete}..."):
                deleted_count = delete_by_source_file(file_to_delete, collection_name)
            
            if deleted_count > 0:
                st.success(f"âœ… å·²ä»çŸ¥è¯†åº“ä¸­åˆ é™¤ {deleted_count} ä¸ªä¸ {file_to_delete} ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ")
            else:
                st.warning(f"âš ï¸ æœªæ‰¾åˆ°ä¸ {file_to_delete} ç›¸å…³çš„æ–‡æ¡£")
        except Exception as e:
            st.error(f"âŒ åˆ é™¤æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")

# ä¸»ç•Œé¢ - é—®ç­”åŠŸèƒ½
st.header("ğŸ’¬ ä¸çŸ¥è¯†åº“å¯¹è¯")

# é—®é¢˜è¾“å…¥
question = st.text_input("è¾“å…¥æ‚¨çš„é—®é¢˜:", placeholder="åœ¨è¿™é‡Œè¾“å…¥æ‚¨æƒ³é—®çš„é—®é¢˜...")

# æŸ¥è¯¢æŒ‰é’®
if st.button("ğŸ” æŸ¥è¯¢", use_container_width=True):
    if question:
        with st.spinner("æ­£åœ¨æŸ¥è¯¢çŸ¥è¯†åº“..."):
            try:
                # ä½¿ç”¨ç°æœ‰å‡½æ•°æŸ¥è¯¢çŸ¥è¯†åº“
                similar_docs = query_vector_db(question, collection_name)
                
                if similar_docs:
                    # ç»„ç»‡ç­”æ¡ˆ
                    response = f"æ ¹æ®çŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯ï¼Œä¸ºæ‚¨æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³å†…å®¹ï¼š\n\n"
                    for i, doc in enumerate(similar_docs, 1):
                        content = doc.page_content.replace('\n', ' ')[:500]  # é™åˆ¶é•¿åº¦
                        response += f"**ç›¸å…³æ®µè½ {i}:**\n{content}...\n\n"
                        
                        # æ˜¾ç¤ºæ¥æºä¿¡æ¯
                        source = doc.metadata.get('source', 'Unknown')
                        if 'source_file' in doc.metadata:
                            source = doc.metadata['source_file']
                        response += f"*æ¥æº: {source}*\n\n"
                else:
                    response = "æŠ±æ­‰ï¼Œæœªèƒ½åœ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›¸å…³çš„å†…å®¹ã€‚è¯·å°è¯•å…¶ä»–é—®é¢˜æˆ–æ·»åŠ æ›´å¤šæ–‡æ¡£åˆ°çŸ¥è¯†åº“ä¸­ã€‚"
                
                # æ˜¾ç¤ºç­”æ¡ˆ
                st.subheader("ğŸ¤– å›ç­”:")
                st.write(response)
            except Exception as e:
                st.error(f"âŒ æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}")
                st.info("è¯·ç¡®ä¿æ‚¨å·²ç»å®‰è£…äº†å¿…è¦çš„ä¾èµ–å¹¶æ­£ç¡®å®ç°äº†æŸ¥è¯¢åŠŸèƒ½")
    else:
        st.warning("è¯·è¾“å…¥ä¸€ä¸ªé—®é¢˜")

# æ˜¾ç¤ºå½“å‰çŸ¥è¯†åº“çŠ¶æ€
st.markdown("---")
st.header("ğŸ“Š çŸ¥è¯†åº“çŠ¶æ€")

if st.button("ğŸ“ˆ è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯", use_container_width=True):
    # ä»å‘é‡æ•°æ®åº“è·å–ç»Ÿè®¡ä¿¡æ¯
    try:
        vectorstore = load_vector_db(collection_name)
        
        if vectorstore:
            doc_count = vectorstore._collection.count()
            
            st.success(f"ğŸ“ é›†åˆ '{collection_name}' åŒ…å« {doc_count} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
            
            # å°è¯•è·å–å”¯ä¸€æºæ–‡ä»¶åˆ—è¡¨
            all_docs = vectorstore.get()
            unique_sources = set()
            
            for doc in all_docs['metadatas']:
                if 'source_file' in doc:
                    unique_sources.add(doc['source_file'])
            
            if unique_sources:
                st.info(f"ğŸ“š çŸ¥è¯†åº“ä¸­åŒ…å«ä»¥ä¸‹æ–‡ä»¶: {', '.join(list(unique_sources))}")
            else:
                st.info("ğŸ’¡ çŸ¥è¯†åº“ä¸­æš‚æ— æ–‡æ¡£æ–‡ä»¶ä¿¡æ¯")
        else:
            st.warning("âš ï¸ æ— æ³•åŠ è½½çŸ¥è¯†åº“ï¼Œè¯·ç¡®ä¿æ•°æ®åº“è·¯å¾„æ­£ç¡®ä¸”å·²æ·»åŠ æ–‡æ¡£")
    except Exception as e:
        st.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")

# åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.caption("ğŸ’¡ æç¤º: è¿™æ˜¯ä¸€ä¸ªç®€å•çš„çŸ¥è¯†åº“ç®¡ç†ç•Œé¢ï¼Œæ‚¨å¯ä»¥ä¸Šä¼ æ–‡æ¡£ã€åˆ é™¤æ–‡æ¡£å¹¶æå‡ºé—®é¢˜")